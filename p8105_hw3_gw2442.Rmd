---
title: "p8105_hw3_gw2442"
output: github_document
date: "2022-10-07"
---
```{r}
library(tidyverse)
library(patchwork)
```

## Problem 1 

```{r}
library(p8105.datasets)
data("instacart")

instacart %>%
  group_by(aisle_id) %>%
  summarise(n_obs = n()) %>%
  arrange(desc(n_obs))
```
There are 134 aisle. The aisle with the most items ordered from were:

 * Aisle 83 with 150,609 items
 * Aisle 24 with 150,473 items
 * Aisle 123 with 78,493 items

```{r}
instacart %>%
  group_by(aisle_id) %>%
  mutate(
    n_obs = n()
  ) %>%
  filter(n_obs > 10000) %>%
ggplot(aes(x = aisle_id, y = n_obs)) +
  geom_point()
```

```{r}
instacart %>%
  filter(aisle == c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>%
  group_by(aisle, product_name) %>%
  summarise(n_obs = n()) 

```

## Problem 2

Loading, tidying, and wrangling the dataset:
```{r}
accel_data = read_csv("data/accel_data.csv") %>%
  janitor::clean_names() %>%
  mutate(
    day_type = ifelse(day %in% c("Saturday", "Sunday"), "weekend", "weekday")) %>%
  select(week, day_id, day, day_type, everything()) %>%
  pivot_longer(
    activity_1:activity_1440,
    names_to = "activity_number",
    names_prefix = "activity_",
    names_transform = list(activity_number = as.numeric),
    values_to = "activity_count_min"
  ) 

skimr::skim(accel_data)
```
The dataset consists of the following variables: week, day_id, day, day_type, activity_number, and activity_count_min. All variables are numeric variables except for day and day_type. The dataset is made up of 50400 rows and 6 columns. 

```{r}
accel_data %>%
  group_by(day_id) %>%
  mutate(
    activity_total = sum(activity_count_min)
  ) %>%
  summarise(day, activity_total) %>%
  distinct %>%
  print(n = 35)
```
From this table, there are no obvious trends apparent. However, two of the Saturdays (day_id = 24, 31) both have a total activity of 1440 minutes. 

```{r}
accel_data %>%
  mutate(
    week = as.character(week)
  ) %>%
  ggplot(aes(x = activity_number, y = activity_count_min, color = week)) + 
  geom_point(alpha = 0.5) +
  labs(
    title = "24 Hour Activity Time Plot",
    x = "Minutes",
    y = "Activity Count"
  )
```
Activity seems to spike around minute 650 and 1250 for weeks 1, 2, 3, and 4. Weeks 1 and 2 also demonstrate a spike in activity during minute 1000. For week 5, activity seems to spike around minute 400 and 1250. Based on this graph, the 63-year old male with BMI 25 demonstrates a rather consistent daily routine for the 5 recorded weeks. 


## Problem 3 

Description of the dataset
```{r}
library(p8105.datasets)
data("ny_noaa")
skimr::skim(ny_noaa)
```
There are 2595176 rows and 7 columns in this dataset. The variables within the dataset are: id, date, prcp, snow, snwd, tmax, and tmin. There are 1134358 missing data points for tmax, 1134420 missing data points for tmin, 145838 missing data poitns for prcp, 381221 missing data points for snow, and 591786 missing data points for snwd. 

```{r}
problem_3 = 
ny_noaa %>%
  janitor::clean_names() %>%
  separate(date, c("year", "month", "day"), sep = "-") %>%
  mutate(
    year = as.numeric(year),
    month = as.numeric(month),
    day = as.numeric(day),
    prcp = prcp/10,
    tmax = as.numeric(tmax),
    tmin = as.numeric(tmin),
    tmax = tmax/10,
    tmin = tmin/10
  ) 

problem_3 %>%
  count(snow, name = "n_obs_snow")
```
The most commonly observed value is 0mm of snowfall. This is observed 2008508 times in the dataset. This makes sense, as snow is not an often weather occurrence, and most days there is no snowfall in New York. 

```{r}
max_temp_jan = 
  problem_3 %>%
  filter(month == 01) %>%
  drop_na(tmax) %>%
  group_by(id) %>%
  summarise(
    mean_tmax = mean(tmax)) 

max_temp_july = 
  problem_3 %>%
  filter(month == 07) %>%
  drop_na(tmax) %>%
  group_by(id) %>%
  summarise(
    mean_tmax = mean(tmax)) 

  ggplot(data = max_temp_jan, aes(x = id, y = mean_tmax)) +
  geom_point() +
  scale_y_continuous(
    limits = c(-20, 40)) +
  labs(
    title = "Average max temp (C) in January",
    x = "Station ID",
    y = "Average max temp (C)") +
    
  ggplot(data = max_temp_july, aes(x = id, y = mean_tmax)) + 
  geom_point() +
  scale_y_continuous(
    limits = c(-20, 40)) +
  labs(
    title = "Average max temp (C) in July",
    x = "Station ID",
    y = "Average max temp (C)") 
```
The two-panel plot demonstrates that the average max temperature in January has remained around 0C across the years, with a couple outliers around -15C. The plot also demonstrates that the average max temperature in July has remained around 25C across the years. 


```{r}
tmax_vs_tmin =
  problem_3 %>%
  select(tmax, tmin) %>%
  drop_na(tmax, tmin) %>%
  pivot_longer(
    tmax:tmin,
    names_to = "observation",
    values_to = "temp")

snow_fall =
  problem_3 %>%
  filter(0 < snow ,
         snow < 100) %>%
  group_by(year) 


ggplot(data = tmax_vs_tmin, aes(x = temp, fill = observation)) +
  geom_density(alpha = 0.5) +
  viridis::scale_fill_viridis(discrete = TRUE) +
  labs(
    title = "Tmax vs Tmin",
    x = "Temp (C)") +

 ggplot(data = snow_fall, aes(group = year, x = year, y = snow)) + 
   geom_boxplot() +
   labs(
    title = "Distribution of snowfall values greater than 0 and less than 100 by year",
    x = "Year",
    y = "Snow Fall (mm)") 
```



